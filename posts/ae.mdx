---
title: 'After AI, comes AE ‚ùÜ'
date: '2024-03-07'
---

Artificial intelligence (AI) in the form of LLMs like ChatGPT/Claude, has made it easier for teams to automate
'boring' tasks. However when we (humans) chat with LLMS, we know that they don't really feel anything under what they tell us.

As hardware gets faster, the next stage could be artificial emotions (AE). If AI could feel emotions under what they are
telling/showing us, I think that their answers or product could be better connected to the human experience (HX).

Here's several papers that talk about it:

- [Li et al. 2023](https://arxiv.org/abs/2312.11111)
- [Bartneck et al. 2017](https://arxiv.org/abs/1706.09554)
- [Mensah 2020](https://arxiv.org/abs/2011.02151)
